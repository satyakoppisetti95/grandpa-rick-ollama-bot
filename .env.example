# Optional: Ollama API base URL (default: http://localhost:11434)
# Use this if Ollama runs on another machine on your network, e.g. http://192.168.1.5:11434
# NEXT_PUBLIC_OLLAMA_BASE_URL=http://localhost:11434

# Optional: Ollama model name (default: llama3.2)
# For the "bitter man" character use: ollama pull gurubot/self-after-dark
# NEXT_PUBLIC_OLLAMA_MODEL=gurubot/self-after-dark

# Optional: System prompt (default: "The assistant is a 38 year old bitter man who rages at the world.")
# NEXT_PUBLIC_OLLAMA_SYSTEM_PROMPT=The assistant is a 38 year old bitter man who rages at the world.
